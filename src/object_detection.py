# -*- coding: utf-8 -*-
"""Object detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb

##### Copyright 2018 The TensorFlow Hub Authors.

Licensed under the Apache License, Version 2.0 (the "License");
"""

# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

"""# Object Detection

<table class="tfo-notebook-buttons" align="left">
  <td>
    <a target="_blank" href="https://www.tensorflow.org/hub/tutorials/object_detection"><img src="https://www.tensorflow.org/images/tf_logo_32px.png" />View on TensorFlow.org</a>
  </td>
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb"><img src="https://www.tensorflow.org/images/colab_logo_32px.png" />Run in Google Colab</a>
  </td>
  <td>
    <a target="_blank" href="https://github.com/tensorflow/hub/blob/master/examples/colab/object_detection.ipynb"><img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />View on GitHub</a>
  </td>
  <td>
    <a href="https://storage.googleapis.com/tensorflow_docs/hub/examples/colab/object_detection.ipynb"><img src="https://www.tensorflow.org/images/download_logo_32px.png" />Download notebook</a>
  </td>
  <td>
    <a href="https://tfhub.dev/s?q=google%2Ffaster_rcnn%2Fopenimages_v4%2Finception_resnet_v2%2F1%20OR%20google%2Ffaster_rcnn%2Fopenimages_v4%2Finception_resnet_v2%2F1"><img src="https://www.tensorflow.org/images/hub_logo_32px.png" />See TF Hub models</a>
  </td>
</table>

This Colab demonstrates use of a TF-Hub module trained to perform object detection.

## Setup
"""

#@title Imports and function definitions

# For running inference on the TF-Hub module.
import tensorflow as tf

import tensorflow_hub as hub

# For downloading the image.
import matplotlib.pyplot as plt
import tempfile
from six.moves.urllib.request import urlopen
from six import BytesIO

# For drawing onto the image.
import numpy as np
from PIL import Image
from PIL import ImageColor
from PIL import ImageDraw
from PIL import ImageFont
from PIL import ImageOps
from PIL import ExifTags

# For measuring the inference time.
import time

import sys, os
import pandas as pd

# Print Tensorflow version
print(tf.__version__)

# Check available GPU devices.
print("The following GPU devices are available: %s" % tf.test.gpu_device_name())

"""## Example use

### Helper functions for downloading images and for visualization.

Visualization code adapted from [TF object detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/utils/visualization_utils.py) for the simplest required functionality.
"""

def display_image(image):
  fig = plt.figure(figsize=(20, 15))
  plt.grid(False)
  plt.imshow(image)
  plt.show()


def download_and_resize_image(url, new_width=256, new_height=256,
                              display=False):
  _, filename = tempfile.mkstemp(suffix=".jpg")
  response = urlopen(url)
  image_data = response.read()
  image_data = BytesIO(image_data)
  pil_image = Image.open(image_data)
  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)
  pil_image_rgb = pil_image.convert("RGB")
  pil_image_rgb.save(filename, format="JPEG", quality=90)
  print("Image downloaded to %s." % filename)
  if display:
    display_image(pil_image)
  return filename


def listdir_by_ext(directory, extension=None, omit_directory=False):

  if extension is None:

    fns = os.listdir(directory)

  elif omit_directory:

    fns =  [x for x in os.listdir(directory)
        if os.path.splitext(x)[-1] == extension]

  else:

    fns = [os.path.join(directory, x) for x in os.listdir(directory)
        if os.path.splitext(x)[-1] == extension]

  return fns


def image_from_file_or_npy(fn, shape=(224, 224), normalize=True):

  fn_npy = os.path.splitext(fn)[0] + '.npy'

  if os.path.isfile(fn_npy):

    imagearr = np.load(fn_npy)

    if not normalize:
      imagearr = (imagearr + 1) * 127.5

    return imagearr

  elif os.path.isfile(fn):

    imagearr = image_from_file(fn, shape=shape, normalize=True)
    np.save(fn_npy, imagearr)

    if not normalize:
      imagearr = (imagearr + 1) * 127.5

    return imagearr

  else:

    print(fn, 'not found; returning array of zeros')
    return np.zeros(shape + (3, ))


def image_from_file(fn, shape=(224, 224), normalize=True):
  """Get raw image from filename"""
  
  with Image.open(fn) as image:

    try:

      #image = ImageOps.exif_transpose(image)
      image = correct_orientation(image)

    except:

      pass

    image = image.resize(shape, resample=Image.BILINEAR)
    
    imagearr = np.array(image, dtype='f')

    if np.shape(imagearr)[-1] == 4:

      imagearr = imagearr[:, :, :3]
  
  if normalize:
    
    return imagearr / 127.5 - 1
  
  else:
    
    return imagearr


def images_from_files(fns, shape, normalize=True, use_npy=True):
  """Get stack of images from filenames"""
  if len(np.shape(fns)) == 1:
    if use_npy:
      return np.stack([image_from_file_or_npy(
        fn, shape, normalize=normalize) for fn in fns])
    else:
      return np.stack([image_from_file(
        fn, shape, normalize=normalize) for fn in fns])
  else:
    return np.stack([images_from_files(
      fn, shape, normalize=normalize) for fn in fns])


for ORIENTATION_TAG in ExifTags.TAGS.keys():
  if ExifTags.TAGS[ORIENTATION_TAG]=='Orientation':
    break


def get_batches(arr, batch_size=1):
    l = len(arr)
    for ndx in range(0, l, batch_size):
        yield arr[ndx:min(ndx + batch_size, l)]


def process_fns(fns):

  images = images_from_files(fns, (640, 480))


def correct_orientation(image):

  try:
    
    exif=dict(image._getexif().items())

    if exif[ORIENTATION_TAG] == 3:
      image=image.rotate(180, expand=True)
    elif exif[ORIENTATION_TAG] == 6:
      image=image.rotate(270, expand=True)
    elif exif[ORIENTATION_TAG] == 8:
      image=image.rotate(90, expand=True)

  except (AttributeError, KeyError, IndexError):
    # cases: image don't have getexif
    pass

  return image


def draw_bounding_box_on_image(image,
                               ymin,
                               xmin,
                               ymax,
                               xmax,
                               color,
                               font,
                               thickness=4,
                               display_str_list=()):
  """Adds a bounding box to an image."""
  draw = ImageDraw.Draw(image)
  im_width, im_height = image.size
  (left, right, top, bottom) = (xmin * im_width, xmax * im_width,
                                ymin * im_height, ymax * im_height)
  draw.line([(left, top), (left, bottom), (right, bottom), (right, top),
             (left, top)],
            width=thickness,
            fill=color)

  # If the total height of the display strings added to the top of the bounding
  # box exceeds the top of the image, stack the strings below the bounding box
  # instead of above.
  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]
  # Each display_str has a top and bottom margin of 0.05x.
  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)

  if top > total_display_str_height:
    text_bottom = top
  else:
    text_bottom = top + total_display_str_height
  # Reverse list and print from bottom to top.
  for display_str in display_str_list[::-1]:
    text_width, text_height = font.getsize(display_str)
    margin = np.ceil(0.05 * text_height)
    draw.rectangle([(left, text_bottom - text_height - 2 * margin),
                    (left + text_width, text_bottom)],
                   fill=color)
    draw.text((left + margin, text_bottom - text_height - margin),
              display_str,
              fill="black",
              font=font)
    text_bottom -= text_height - 2 * margin


def draw_boxes(image, boxes, class_names, scores, max_boxes=10, min_score=0.1):
  """Overlay labeled boxes on an image with formatted scores and label names."""
  colors = list(ImageColor.colormap.values())

  try:
    font = ImageFont.truetype("/usr/share/fonts/truetype/liberation/LiberationSansNarrow-Regular.ttf",
                              25)
  except IOError:
    print("Font not found, using default font.")
    font = ImageFont.load_default()

  for i in range(min(boxes.shape[0], max_boxes)):
    if scores[i] >= min_score:
      ymin, xmin, ymax, xmax = tuple(boxes[i])
      display_str = "{}: {}%".format(class_names[i].decode("ascii"),
                                     int(100 * scores[i]))
      color = colors[hash(class_names[i]) % len(colors)]
      image_pil = Image.fromarray(np.uint8(image)).convert("RGB")
      draw_bounding_box_on_image(
          image_pil,
          ymin,
          xmin,
          ymax,
          xmax,
          color,
          font,
          display_str_list=[display_str])
      np.copyto(image, np.array(image_pil))
  return image


def load_img(path):
  img = tf.io.read_file(path)
  img = tf.image.decode_jpeg(img, channels=3)
  return img

def run_detector(detector, path_or_image, from_path=False):

  if from_path:
    img = load_img(path_or_image)
    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]
  else:
    converted_img  = tf.image.convert_image_dtype(path_or_image, tf.float32)[tf.newaxis, ...]

  start_time = time.time()
  result = detector(converted_img)
  end_time = time.time()

  result = {key:value.numpy() for key,value in result.items()}

  return result


def main():

  module_handle = "https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1" #@param ["https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1", "https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1"]
  detector = hub.load(module_handle).signatures['default']

  if len(sys.argv) < 2:

    image_urls = [
      # Source: https://commons.wikimedia.org/wiki/File:The_Coleoptera_of_the_British_islands_(Plate_125)_(8592917784).jpg
      "https://upload.wikimedia.org/wikipedia/commons/1/1b/The_Coleoptera_of_the_British_islands_%28Plate_125%29_%288592917784%29.jpg",
      # By Américo Toledano, Source: https://commons.wikimedia.org/wiki/File:Biblioteca_Maim%C3%B3nides,_Campus_Universitario_de_Rabanales_007.jpg
      "https://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg/1024px-Biblioteca_Maim%C3%B3nides%2C_Campus_Universitario_de_Rabanales_007.jpg",
      # Source: https://commons.wikimedia.org/wiki/File:The_smaller_British_birds_(8053836633).jpg
      "https://upload.wikimedia.org/wikipedia/commons/0/09/The_smaller_British_birds_%288053836633%29.jpg",
      ]

    def detect_img(image_url, min_detect_score=0.1):
      start_time = time.time()
      image_path = download_and_resize_image(image_url, 640, 480)
      result = run_detector(detector, image_path, from_path=True)
      print([
        ent.decode('utf-8')
        for ent, score in zip(result['detection_class_entities'], result['detection_scores'])
        if score > min_detect_score
        ])
      end_time = time.time()
      print("Inference time:",end_time-start_time)

    detect_img(image_urls[0])
    detect_img(image_urls[1])
    detect_img(image_urls[2])

  elif len(sys.argv) == 2:

    filenames = listdir_by_ext(sys.argv[1], extension='.jpg')
    print(filenames)

    def process_images(fns, min_detect_score=0.1):

      results = []

      for fn in fns:

        result = run_detector(detector, image_from_file(fn, (640, 480)))

        results.extend([
          {'filename': fn, 'object': ent.decode('utf-8')}
          for ent, score in zip(result['detection_class_entities'], result['detection_scores'])
          if score > min_detect_score
        ])

      return results

    results = process_images(filenames)

    print(results)

    pd.DataFrame(results).to_csv('results.csv')

  else:

    warn('Usage: python object_detection.py [directory]')


if __name__ == '__main__':
  main()